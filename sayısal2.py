# -*- coding: utf-8 -*-
"""sayısal2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12cwDjy8iNshKp_-kGfRuSHLXZSHKTMzz
"""

### Load necessary libraries ###
import glob
import os
import librosa
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score

import tensorflow as tf
from tensorflow import keras



def extract_features(parent_dir, sub_dirs, file_ext="*.wav", bands=60, frames=41):
    def _windows(data, window_size):
        start = 0
        while start < len(data):
            yield int(start), int(start + window_size)
            start += (window_size // 2)

    window_size = 512 * (frames - 1)
    features, labels = [], []
    for sub_dir in sub_dirs:
        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):
            segment_log_specgrams, segment_labels = [], []
            sound_clip, sr = librosa.load(fn)
            label = int(fn.split('-')[1])
            for (start, end) in _windows(sound_clip, window_size):
                if len(sound_clip[start:end]) == window_size:
                    signal = sound_clip[start:end]
                    melspec = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=bands)
                    logspec = librosa.amplitude_to_db(melspec)
                    logspec = logspec.T.flatten()[:, np.newaxis].T
                    segment_log_specgrams.append(logspec)
                    segment_labels.append(label)

            segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(
                len(segment_log_specgrams), bands, frames, 1)
            segment_features = np.concatenate(
                (segment_log_specgrams, np.zeros(np.shape(segment_log_specgrams))), axis=3)
            for i in range(len(segment_features)):
                segment_features[i, :, :, 1] = librosa.feature.delta(
                    segment_features[i, :, :, 0])

            if len(segment_features) > 0:
                features.append(segment_features)
                labels.append(segment_labels)
    return features, labels

print(len(features))
print(len(labels))

### Define helper functions ###
def extract_features(parent_dir,sub_dirs,file_ext="*.wav",
                     bands=60,frames=41):
    def _windows(data, window_size):
        start = 0
        while start < len(data):
            yield int(start), int(start + window_size)
            start += (window_size // 2)

    window_size = 512 * (frames - 1)
    features, labels = [], []
    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):
        segment_log_specgrams, segment_labels = [], []
        sound_clip,sr = librosa.load(fn)
        label = int(fn.split('/')[2].split('-')[1])
        for (start,end) in _windows(sound_clip,window_size):
            if(len(sound_clip[start:end]) == window_size):
                signal = sound_clip[start:end]
                melspec = librosa.feature.melspectrogram(signal,n_mels=bands)
                logspec = librosa.amplitude_to_db(melspec)
                logspec = logspec.T.flatten()[:, np.newaxis].T
                segment_log_specgrams.append(logspec)
                segment_labels.append(label)

        segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(
            len(segment_log_specgrams),bands,frames,1)
        segment_features = np.concatenate((segment_log_specgrams, np.zeros(
            np.shape(segment_log_specgrams))), axis=3)
        for i in range(len(segment_features)):
            segment_features[i, :, :, 1] = librosa.feature.delta(
                segment_features[i, :, :, 0])

        if len(segment_features) > 0: # check for empty segments
            features.append(segment_features)
            labels.append(segment_labels)
    return features, labels

from google.colab import drive
drive.mount("/content/drive")

import librosa
trainPath="/content/drive/MyDrive/sayısal/UrbanSound8K/audio/fold3/6988-5-0-1.wav" # ses dosyasının tam yolunu içerir
audio_file_path=trainPath
librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)
#eklenti

from IPython.display import Audio
Audio("/content/drive/MyDrive/sayısal/UrbanSound8K/audio/fold3/6988-5-0-1.wav")
#eklenti

print(librosa_audio_data)
#eklenti

parent_dir = '/content/drive/MyDrive/sayısal/UrbanSound8K/audio/'
save_dir = '/content/drive/MyDrive/sayısal/UrbanSound8K/processed/'
os.makedirs(save_dir, exist_ok=True)

sub_dirs = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5',
             'fold6', 'fold7', 'fold8', 'fold9', 'fold10']

features, labels = extract_features(parent_dir, sub_dirs)

for i, sub_dir in enumerate(sub_dirs):
    np.savez(os.path.join(save_dir, f'{sub_dir}.npz'),
             features=features[i], labels=labels[i])

save_dir = '/content/drive/MyDrive/sayısal/UrbanSound8K/processed/'
os.makedirs(save_dir, exist_ok=True)
#eklenti

parent_dir = '/content/drive/MyDrive/sayısal/UrbanSound8K/audio/'
save_dir = "/content/drive/MyDrive/sayısal/UrbanSound8K/processed/"
folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',
                  'fold5','fold6','fold7','fold8',
                  'fold9','fold10'])
for sub_dir in sub_dirs:
    features, labels = extract_features(parent_dir,sub_dir)
    np.savez("{0}{1}".format(save_dir, sub_dir),
             features=features,
             labels=labels)

print(save_dir)
#eklenti

## Define convolutional network architecture ###
def get_network():
    num_filters = [24,32,64,128]
    pool_size = (2, 2)
    kernel_size = (3, 3)
    input_shape = (60, 41, 2)
    num_classes = 10
    keras.backend.clear_session()

    model = keras.models.Sequential()
    model.add(keras.layers.Conv2D(24, kernel_size,
                padding="same", input_shape=input_shape))
    model.add(keras.layers.BatchNormalization())
    model.add(keras.layers.Activation("relu"))
    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))

    model.add(keras.layers.Conv2D(32, kernel_size,
                                  padding="same"))
    model.add(keras.layers.BatchNormalization())
    model.add(keras.layers.Activation("relu"))
    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))

    model.add(keras.layers.Conv2D(64, kernel_size,
                                  padding="same"))
    model.add(keras.layers.BatchNormalization())
    model.add(keras.layers.Activation("relu"))
    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))

    model.add(keras.layers.Conv2D(128, kernel_size,
                                  padding="same"))
    model.add(keras.layers.BatchNormalization())
    model.add(keras.layers.Activation("relu"))

    model.add(keras.layers.GlobalMaxPooling2D())
    model.add(keras.layers.Dense(128, activation="relu"))
    model.add(keras.layers.Dense(num_classes, activation="softmax"))

    model.compile(optimizer=keras.optimizers.Adam(1e-4),
        loss=keras.losses.SparseCategoricalCrossentropy(),
        metrics=["accuracy"])
    return model

import tensorflow as tf
print(tf.__version__)

# kodumuz için gerekli olan kütüphaneleri çağırıyoruz
import matplotlib.pyplot as plt
import pandas as pd
import os
import librosa
import numpy as np

from tqdm import tqdm

!pip install resampy

def feature_extractor(file_path):
    audio, sample_rate = librosa.load(file_path, res_type="kaiser_fast")
    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)

    return mfccs_scaled_features

metadata_path = "/content/drive/MyDrive/sayısal/UrbanSound8K/metadata/UrbanSound8K.csv"
audio_dataset_path = "/content/drive/MyDrive/sayısal/UrbanSound8K/audio/"
metadata = pd.read_csv(metadata_path)

extracted_features = []

# Her bir ses dosyası için özellik çıkarımı yap
for index, row in tqdm(metadata.iterrows()):
    file_name = os.path.join(audio_dataset_path, "fold" + str(row["fold"]), str(row["slice_file_name"]))
    final_class_labels = row["class"]
    data = feature_extractor(file_name)
    extracted_features.append([data, final_class_labels])

x_train, y_train = [], []
for ind in train_index:
    # ses dosyasının özelliklerini veya segmentlerini okuyun
    train_data = np.load(os.path.join(load_dir, f'{folds[ind]}.npz'), allow_pickle=True)
    features = train_data["features"]
    labels = train_data["labels"]
    x_train.append(features)
    y_train.append(labels)

# tüm eğitim katmanlarının x,y çiftlerini birleştirin
x_train = np.concatenate(x_train, axis=0).astype(np.float32)
y_train = np.concatenate(y_train, axis=0).astype(np.float32)

test_data = np.load(os.path.join(load_dir, f'{folds[test_index][0]}.npz'), allow_pickle=True)
x_test = test_data["features"]
y_test = test_data["labels"]

import os

load_dir = "/content/drive/MyDrive/sayısal/UrbanSound8K/processed/"
for filename in os.listdir(load_dir):
    if filename.endswith(".npz"):
        file_path = os.path.join(load_dir, filename)
        data = np.load(file_path, allow_pickle=True)
        features = data["features"]
        labels = data["labels"]
        print(f"Loaded {filename}: features shape={features.shape}, labels shape={labels.shape}")

accuracies = []
folds = np.array(['fold1', 'fold2', 'fold3', 'fold4',
                  'fold5', 'fold6', 'fold7', 'fold8',
                  'fold9', 'fold10'])
load_dir = "/content/drive/MyDrive/sayısal/UrbanSound8K/processed/"
kf = KFold(n_splits=10)
for train_index, test_index in kf.split(folds):
    x_train, y_train = [], []
    for ind in train_index:
        # özellikleri veya segmentleri okuyun
        train_data = np.load(os.path.join(load_dir, f'{folds[ind]}.npz'), allow_pickle=True)
        features = train_data["features"]
        labels = train_data["labels"]
        for i in range(len(features)):
            x_train.append(features[i])
            y_train.append(labels[i])

    # tüm eğitim veri kümelerinin x, y çiftlerini birleştirin
    x_train = np.concatenate(x_train, axis=0).astype(np.float32)
    y_train = np.concatenate(y_train, axis=0).astype(np.float32)

    # test veri kümesindeki her bir segment üzerinde tahmin yapacağız
    test_data = np.load(os.path.join(load_dir, f'{folds[test_index][0]}.npz'), allow_pickle=True)
    x_test = test_data["features"]
    y_test = test_data["labels"]

    model = get_network()
    model.fit(x_train, y_train, epochs=50, batch_size=24, verbose=0)

    # test setini/foldunu değerlendirin
    y_true, y_pred = [], []
    for x, y in zip(x_test, y_test):
        # ses klibinin segmentlerine göre tahminleri ortalama alın
        avg_p = np.argmax(np.mean(model.predict(x), axis=0))
        y_pred.append(avg_p)
        # ses klibi için tek bir etiketi np.unique ile seçin
        y_true.append(np.unique(y)[0])
    accuracies.append(accuracy_score(y_true, y_pred))
print("Ortalama 10 Kat Doğruluk: {0}".format(np.mean(accuracies)))

### Train and evaluate via 10-Folds cross-validation ###
accuracies = []
folds = np.array(['fold1','fold2','fold3','fold4',
                  'fold5','fold6','fold7','fold8',
                  'fold9','fold10'])
load_dir = "/content/drive/MyDrive/sayısal/UrbanSound8K/processed/"
kf = KFold(n_splits=10)
for train_index, test_index in kf.split(folds):
    x_train, y_train = [], []
    for ind in train_index:
        # read features or segments of an audio file
        train_data = np.load(os.path.join(load_dir, f'{folds[ind]}.npz'), allow_pickle=True)
       # train_data = np.load("{0}/{1}.npz".format(load_dir,folds[ind]),
                  #     allow_pickle=True)
        # for training stack all the segments so that they are treated as an example/instance
        features = np.concatenate(train_data["features"], axis=0)
        labels = np.concatenate([train_data["labels"]] * features.shape[0], axis=0)
        #labels = np.concatenate(train_data["labels"], axis=0)
        x_train.append(features)
        y_train.append(labels)
    # stack x,y pairs of all training folds
    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)
    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)

    # for testing we will make predictions on each segment and average them to
    # produce signle label for an entire sound clip.
    test_data = np.load("{0}/{1}.npz".format(load_dir,
                   folds[test_index][0]), allow_pickle=True)
    x_test = test_data["features"]
    y_test = test_data["labels"]

    model = get_network()
    model.fit(x_train, y_train, epochs = 50, batch_size = 24, verbose = 0)

    # evaluate on test set/fold
    y_true, y_pred = [], []
    for x, y in zip(x_test, y_test):
        # average predictions over segments of a sound clip
        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))
        y_pred.append(avg_p)
        # pick single label via np.unique for a sound clip
        y_true.append(np.unique(y)[0])
    accuracies.append(accuracy_score(y_true, y_pred))
print("Average 10 Folds Accuracy: {0}".format(np.mean(accuracies)))

for train_index, test_index in kf.split(folds):
    x_train, y_train = [], []
    for ind in train_index:
        train_data = np.load("{0}/{1}.npz".format(load_dir, folds[ind]), allow_pickle=True)
        features = train_data["features"]
        labels = train_data["labels"]

        # Boş dizileri kontrol et
        if features.size == 0 or labels.size == 0:
            continue

        features = np.concatenate(features, axis=0)
        labels = np.concatenate(labels, axis=0)

        x_train.append(features)
        y_train.append(labels)

    # x_train ve y_train boş ise bir sonraki döngüye geç
    if len(x_train) == 0 or len(y_train) == 0:
        continue

    x_train = np.concatenate(x_train, axis=0).astype(np.float32)
    y_train = np.concatenate(y_train, axis=0).astype(np.float32)

    test_data = np.load("{0}/{1}.npz".format(load_dir, folds[test_index][0]), allow_pickle=True)
    x_test = test_data["features"]
    y_test = test_data["labels"]

    model = get_network()
    model.fit(x_train, y_train, epochs=50, batch_size=24, verbose=0)

    y_true, y_pred = [], []
    for x, y in zip(x_test, y_test):
        avg_p = np.argmax(np.mean(model.predict(x), axis=0))
        y_pred.append(avg_p)
        y_true.append(np.unique(y)[0])
    accuracies.append(accuracy_score(y_true, y_pred))
print("Average 10 Folds Accuracy: {0}".format(np.mean(accuracies)))

x_train, y_train = [], []
for ind in train_index:
    train_data = np.load("{0}/{1}.npz".format(load_dir, folds[ind]),
                   allow_pickle=True)
    features = train_data["features"]
    labels = train_data["labels"]

    # Check if the arrays are empty
    if features.size == 0 or labels.size == 0:
        continue

    features = np.concatenate(features, axis=0)
    labels = np.concatenate(labels, axis=0)

    x_train.append(features)
    y_train.append(labels)

for train_index, test_index in kf.split(folds):
    x_train, y_train = [], []
    for ind in train_index:
        # read features or segments of an audio file
        train_data = np.load("{0}/{1}.npz".format(load_dir, folds[ind]),
                       allow_pickle=True)
        # Check if the arrays are empty
        if train_data["features"].size == 0 or train_data["labels"].size == 0:
            continue

        # for training stack all the segments so that they are treated as an example/instance
        features = np.concatenate(train_data["features"], axis=0)
        labels = np.concatenate(train_data["labels"], axis=0)
        x_train.append(features)
        y_train.append(labels)

    # Check if any valid data exists for training
    if not x_train or not y_train:
        continue